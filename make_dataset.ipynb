{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from blob import blob_analyse_text\n",
    "from transformer import Transformer\n",
    "from lexicon import lexicon_analyse_text\n",
    "import os\n",
    "from PyPDF2 import PdfReader\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ProcessPoolExecutor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "validate the pdfs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "def read_pdfs_in_folder_and_delete_faulty(folder_path):\n",
    "    for file in os.listdir(folder_path):\n",
    "        if file.endswith(\".pdf\"):\n",
    "            try:\n",
    "                pdf_path = os.path.join(folder_path, file)\n",
    "                with open(pdf_path, 'rb') as pdf_file:\n",
    "                    pdf_reader = PdfReader(pdf_file)\n",
    "            #    print(f\"Successfully read {file}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to read {file}: {e}\")\n",
    "                try:\n",
    "                    os.remove(pdf_path)\n",
    "                    print(f\"Deleted faulty file: {file}\")\n",
    "                except Exception as remove_error:\n",
    "                    print(f\"Failed to delete faulty file {file}: {remove_error}\")\n",
    "\n",
    "# Example usage:\n",
    "folder_path = \"./dataset2/ugly2\"\n",
    "read_pdfs_in_folder_and_delete_faulty(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Processor():\n",
    "    def __init__(self, sentiment_processor) -> None:\n",
    "        if sentiment_processor== \"lexicon\":\n",
    "            self.sentiment_processor= lexicon_analyse_text\n",
    "            self.multiprocess=True\n",
    "        elif sentiment_processor== \"transformer\":\n",
    "            transformer=Transformer(model=\"distilbert\")\n",
    "            self.sentiment_processor= transformer.analyse_text\n",
    "            self.multiprocess=False\n",
    "        elif sentiment_processor== \"textBlob\":\n",
    "            self.sentiment_processor= blob_analyse_text\n",
    "            self.multiprocess=True\n",
    "        else:\n",
    "            raise(Exception(\"choice an available processor\"))\n",
    "\n",
    "    def read_file_text(self, file_path):\n",
    "        file_extension = os.path.splitext(file_path)[1].lower()\n",
    "\n",
    "        if file_extension == \".pdf\":\n",
    "            with open(file_path, \"rb\") as pdf_file:\n",
    "                pdf_reader = PdfReader(pdf_file)\n",
    "                text = \" \".join([pdf_reader.pages[i].extract_text() for i in range(len(pdf_reader.pages))])\n",
    "        elif file_extension == \".txt\":\n",
    "            with open(file_path, \"r\") as txt_file:\n",
    "                text = txt_file.read()\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported file type: {file_extension}\")\n",
    "\n",
    "        return text\n",
    "\n",
    "    def moving_average(self, timeseries, window_len):\n",
    "        cumsum = np.cumsum(np.insert(timeseries, 0, 0)) \n",
    "        moving_avg = (cumsum[window_len:] - cumsum[:-window_len]) / float(window_len)\n",
    "        return moving_avg\n",
    "\n",
    "    def process_file(self, file_path, avg_percent=0.01):\n",
    "        raw_text = self.read_file_text(file_path)\n",
    "        avg_window_len= int(len(raw_text) * avg_percent)\n",
    "\n",
    "        timeseries = self.sentiment_processor(raw_text)\n",
    "        timeseries_avg = self.moving_average(timeseries, avg_window_len)\n",
    "        return timeseries_avg\n",
    "\n",
    "    def process(self, folder_path):\n",
    "        files = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith((\".pdf\", \".txt\"))]\n",
    "        timeseries_list = []\n",
    "\n",
    "        print(files[:10])\n",
    "\n",
    "        if(self.multiprocess):\n",
    "            with ProcessPoolExecutor() as executor:\n",
    "                results = executor.map(self.process_file, files)\n",
    "\n",
    "            for result in results:\n",
    "                timeseries_list.append(result)\n",
    "        else:\n",
    "            for file in files:\n",
    "                result= self.process_file(file)\n",
    "                timeseries_list.append(result)\n",
    "                \n",
    "        return timeseries_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_path = \"./dataset2/good\"\n",
    "ugly_path = \"./dataset2/ugly\"\n",
    "min_lenght=40000\n",
    "average_len = 1000  # The window length for moving average\n",
    "window_len=20\n",
    "\n",
    "processor = Processor(\"textBlob\")\n",
    "\n",
    "#good_timeseries = processor.process(good_path )\n",
    "ugly_timeseries = processor.process(ugly_path )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.signal import resample\n",
    "import matplotlib.pyplot as plt\n",
    "def resample_lists_to_arrays(list_of_lists, target_length):\n",
    "    resampled_arrays = []\n",
    "\n",
    "    for sublist in list_of_lists:\n",
    "        # Convert sublist to numpy array\n",
    "        original_array = np.array(sublist)\n",
    "\n",
    "        # Resample the array to the target length\n",
    "        resampled_array = resample(original_array, target_length)\n",
    "\n",
    "        # Add the resampled array to the output list\n",
    "        resampled_arrays.append(resampled_array)\n",
    "\n",
    "    return resampled_arrays\n",
    "\n",
    "\n",
    "def plot_first_n_examples(timeseries_data, n=2):\n",
    "    for i in range(n):\n",
    "        plt.figure()\n",
    "        plt.plot(np.arange(0, len(timeseries_data[i])), timeseries_data[i], label=f'emotional arcs novel={i})')\n",
    "        plt.title(f\"Example {i + 1}\")\n",
    "        plt.xlabel(\"Time\")\n",
    "        plt.ylabel(\"Emotional Score\")\n",
    "        plt.show()\n",
    "\n",
    "target_length = 5000\n",
    "#good_resampled = resample_lists_to_arrays(good_timeseries, target_length)\n",
    "ugly_resampled = resample_lists_to_arrays(ugly_timeseries, target_length)\n",
    "plot_first_n_examples(ugly_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good= np.stack( ugly_resampled, axis=0 )\n",
    "#ugly=np.stack( ugly_resampled, axis=0)\n",
    "\n",
    "with open('./dataset/dataset_ugly_2.npy', 'wb') as f:\n",
    "    np.save(f, good)\n",
    "   # np.save(f, ugly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./dataset/dataset_ugly_1.npy', 'rb') as f:\n",
    "    good2 = np.load(f)\n",
    "   # ugly1 = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l,_ = good.shape\n",
    "print(np.all(good == good2))\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(good.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (default, May 26 2023, 14:05:08) \n[GCC 9.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
